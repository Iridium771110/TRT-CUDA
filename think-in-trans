关于网络训练反传的一些粗鄙思想
基本都是梯度反传的一套，那么和线性优化或者随机梯度下降的ods是否就是同一回事呢？不过这更像是一个系统优化以逼近最优解的过程，数值方法求解函数？


关于网络设计单元的一些粗鄙思想
cnn = conv， conv从数学意义上可以理解为 filter
输入如果作为一个信号来看，即在使用过滤器进行滤波，从时序输入上来讲似乎更容易理解
trans的核心attn在于矩阵相乘，拆开看做 矩阵矢量内积的组合。内积视为投影，可以表征各矢量在本矢量上的相似性（参考余弦相似），因此这个相乘是在找特征矢的相似性（？）
但是操作上似乎是没有单位矢的做法在内，可能这个东西会让模型自行训练吧，也许也是trans难以训练的原因之一？
根号d的除法感觉只是一个工程trick，防止某些异常值溢出或者反传失效之类的事情
看起来soft的目的在于归一化并且同时锐化差距，使最大值更加明显
第二个attn暂时不太懂，为啥要有两次乘法呢

既然内积可以用，那么外积是否也可用（不过外积好像很麻烦来着……）

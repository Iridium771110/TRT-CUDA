有些情况下release模式会产生莫名其妙的错误，往往来自于一些不起眼的warning，在激进优化模式下出现了离奇的问题，常见于不明原因的死循环、段错误等等。
因而至少应当在编译选项中添加 如
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Werror=return-type")
set(CMAKE_CUDA_FLAGS "-Xcompiler -Werror=return-type -fPIC ${CMAKE_CUDA_FLAGS}\
                    -gencode arch=compute_89,code=sm_89 -std=c++17")

TRT-Plugin things
插件形式的编译中，可能出现CMAKE中某些LINK库因为未被扫描到需求而未发生链接（ldd查看无目标链接库）
此时应当使用 target_link_options(name PUBLIC "LINKER:-no-as-needed"),使指定库强行链接
猜测这个情况可能是因为注册机制导致的问题，在使用 CMAKE 编译依赖 libtorch的库时也发生了这个现象
  由于注册机制可以在不包含子类实现及头文件的情况下，仅使用父类头文件及实现库完成编译工作，可能因此导致运行时找不到子类实现但是编译及链接时没有问题（ldd也未出现 undefined symbol）的情况
  该原因仅为猜测

Plugin在各个阶段的运行顺序，针对orin trt10.5.0
buildSerialize：
  construct->suppor-check->clone->config->init->config->enqueue->terminate->destroy
  需要注意从clone开始，执行的是clone后的对象
  log中有很多重复的东西，可能内部有递归
  因为这里对clone对象进行了init，因此不会有下面infer时的init问题
  
inference:
  construct->init->clone->config->enqueue
  需要注意，此时config开始，执行的对象是clone后的那个plugin
  全部执行完毕，本engine需要释放时，clone对象destroy->原始对象terminate->原始对象destroy
  因此如果clone时调用的构造有部分操作在init内，那么可能就会导致clone的和原始对象不同，发生未初始化带来的错误

和网上部分说法可能不同的是，似乎initialize和teminate在调用内部有自关联，可能存在回调情况
configurePlugin方法可以用作部分运行时检查的手段
support-format-combination这里可以用于engine内部中间张量（本plugin的输入输出等）格式、类型等的指定，这个指定可以限定engine build过程中对计算方案的选择范围，不让格式乱飘
部分地方提示，检查设置时可能必须自小向大，不应该以比当前大的索引作为基准来检查自身，而应该以比当前小的索引作为基准检查
部分可参考文档 https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending
Tensor-setAllowedFormat 对内部中间张量不起作用，估计仅对engine输入输出进行设置时起作用
builder = createInferBuilder() 似乎会存在一定的内存泄漏（存疑，数量还不小，cpu内存），delete builder之后内存没有相应减小
plugin选择数据类型应该由输入输出描述子来直接获取而不是一个op attr

高版本如 10.5 存在对attention的图优化算子融合等操作，实际用于Superglue时发现cross-attention部分会造成大比例精度问题（并且部分帧结果不稳定，在两三种结果间跳变）怀疑存在bug
涉及norm类型的layer时，half的精度可能不够，在SuperPoint中发生build-engine时若打开fp16，有时norm部分（pow、sum等节点）全部会选择half，会导致严重的精度问题（输出0、nan等），选择float时结果正确
build-engine应当注意对格式的指定，防止部分莫名其妙错误

注意一些预编译指令的配套使用，可能会发生奇怪位置的段错误
比如 #pragma pack(x) <--> #pragma pack()应配对使用

要分析 DLA，请在使用 NVIDIA Nsight Systems CLI 时添加 --accelerator-trace nvmedia 标志

tensorrt和onnx 对于卷积的权重排布方式为 G-co-ci-kkk
关于部分源文件的下载（BSP）
https://developer.nvidia.com/embedded/jetson-linux-r3541

在矢量操作、tensorcore等操作中，尤其是当指令操作为长字段，但是操作数仅能给首寄存器的时候（注意SASS操作数和PTX操作数之间存在一定的区别，PTX更灵活，寄存器不需要连续，可以编译时重排列），数据存储时的寄存器顺序应当连续，非连续寄存器会导致寄存器间数据移动，产生大量不必要开销（显著的IMAD，MOV类型指令，在大kernel占用率不高的情况下，产生显著的 no instruction stall）
LDGDEPBAR 该barrier和 cp.async.commit_group 似乎是强绑定，但是对延迟的影响待定
block内共享内存超出48k需要使用动态共享内存设置
共享内存进行矢量操作时，似乎会出现随机冲突（指分次采样结果均不同），尤其是16字节操作时。但是进行4字节操作时不会出现冲突，即使bank已经对齐，该问题也可能由于首地址错位/错误而产生，需要经过理论位置排查
8threads 同一全局地址的boardcast会导致 uncoalse L2 和 uncoalse shared，类似于冲突和全局不对齐的行为，因此需要考虑将其均匀分布，减少同一全局位置的广播（在LDGSTS中证实存在这一现象）
异步拷贝可与计算指令执行显式异步（异步指令如LDGSTS，可以显示使用ptx等方式，可以灵活控制，由用户指定），部分同步指令，如ldmatrix与计算指令可以隐式异步（由gpu硬件执行自动指令并行，不可控）。共享内存的异步载入对延迟隐藏的效果较少，而全局内存的异步载入对延迟隐藏有显著的作用，尤其是在载入的循环量较大的时候，此效果更为明显。流水作业可以考虑2-3级
在某些情况下，即使寄存器连续，进行矢量存取时，如果采用cpp高级语言形式操作，可能会出现断裂情况，导致内存效率低下，尤其是在针对全局内存的写操作（这依赖于编译器的编译结果，尚未找到合适的提示手段）。而采用ptx st.global.v4.u32时则不会出现该问题。
ampere指令并行（ILP）依赖于编译器和硬件，触发条件似乎比较玄，当触发时，对于不同单元（如计算和内存，在矩阵乘法中，对ldsm和mma）的执行延迟有良好的掩盖作用，一定程度上可以弥补因占用率不足带来的延迟问题
syncthread 之后进行 ldgsts时，会前置出现3*LDS RZ，此现象和sync的数目强绑定（但是trt中的source显示并没有，不知有什么神奇的操作）
一般f16的结果和误差应当在千分位上，但是最大个体误差可能存在百分位与十分位上
L1与shared处于同一位置，理论上共享同一资源空间，因此行为可能一致。在LDGSTS时ncu报告了非shared指令源头的bank conflict
按照往常经验，LDGSTS自global读取时的内存排布也应遵循类似的bank分离形式，典型的应当采取线程连续读取，随机乱读可能会产生conflict，但是具体形式待实际查验，（可能存在一些异步时的冲突操作？）
实际操作中，发现cp.async在ampere中，当采用循环方式调用的时候，如果循环数未直接指定，则需要在该循环组commit之后进行wait 0,否则即使在后续的异步拷贝组后进行了wait 0,改组似乎也会出现未同步完成拷贝的情况（该现象出现在mha调试中，导致了内部矩阵乘法中首个轮次的结果错误，在采用指定循环数值或者在下一组进行前任意位置进行wait后，结果正确）
对于初始化等操作，当使用低字节精度时（因为一个reg长度是4字节），若非特别指定的类型（如half2,short2），则一个寄存器只会存一个数值，在SASS中会出现大量的PRMT操作，可在初始化时显式使用int类型指针代替，可显著减少指令数（PRMT），但CS2R会有增加，整体是有利的（在mha调整中被证实），副作用似乎会引起寄存器数增加（？）

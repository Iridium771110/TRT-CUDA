TRT-Plugin things
插件形式的编译中，可能出现CMAKE中某些LINK库因为未被扫描到需求而未发生链接（ldd查看无目标链接库）
此时应当使用 target_link_options(name PUBLIC "LINKER:-no-as-needed"),使指定库强行链接
猜测这个情况可能是因为注册机制导致的问题，在使用 CMAKE 编译依赖 libtorch的库时也发生了这个现象
  由于注册机制可以在不包含子类实现及头文件的情况下，仅使用父类头文件及实现库完成编译工作，可能因此导致运行时找不到子类实现但是编译及链接时没有问题（ldd也未出现 undefined symbol）的情况
  该原因仅为猜测

Plugin在各个阶段的运行顺序，针对orin trt10.5.0
buildSerialize：
  construct->suppor-check->clone->config->init->config->enqueue->terminate->destroy
  需要注意从clone开始，执行的是clone后的对象
  log中有很多重复的东西，可能内部有递归
  因为这里对clone对象进行了init，因此不会有下面infer时的init问题
  
inference:
  construct->init->clone->config->enqueue
  需要注意，此时config开始，执行的对象是clone后的那个plugin
  全部执行完毕，本engine需要释放时，clone对象destroy->原始对象terminate->原始对象destroy
  因此如果clone时调用的构造有部分操作在init内，那么可能就会导致clone的和原始对象不同，发生未初始化带来的错误

和网上部分说法可能不同的是，似乎initialize和teminate在调用内部有自关联，可能存在回调情况
configurePlugin方法可以用作部分运行时检查的手段
support-format-combination这里可以用于engine内部中间张量（本plugin的输入输出等）格式、类型等的指定，这个指定可以限定engine build过程中对计算方案的选择范围，不让格式乱飘
部分地方提示，检查设置时可能必须自小向大，不应该以比当前大的索引作为基准来检查自身，而应该以比当前小的索引作为基准检查
部分可参考文档 https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending
Tensor-setAllowedFormat 对内部中间张量不起作用，估计仅对engine输入输出进行设置时起作用
builder = createInferBuilder() 似乎会存在一定的内存泄漏（存疑，数量还不小，cpu内存），delete builder之后内存没有相应减小
plugin选择数据类型应该由输入输出描述子来直接获取而不是一个op attr

高版本如 10.5 存在对attention的图优化算子融合等操作，实际用于Superglue时发现cross-attention部分会造成大比例精度问题（并且部分帧结果不稳定，在两三种结果间跳变）怀疑存在bug
涉及norm类型的layer时，half的精度可能不够，在SuperPoint中发生build-engine时若打开fp16，有时norm部分（pow、sum等节点）全部会选择half，会导致严重的精度问题（输出0、nan等），选择float时结果正确
build-engine应当注意对格式的指定，防止部分莫名其妙错误

注意一些预编译指令的配套使用，可能会发生奇怪位置的段错误
比如 #pragma pack(x) <--> #pragma pack()应配对使用

要分析 DLA，请在使用 NVIDIA Nsight Systems CLI 时添加 --accelerator-trace nvmedia 标志

tensorrt和onnx 对于卷积的权重排布方式为 G-co-ci-kkk
关于部分源文件的下载（BSP）
https://developer.nvidia.com/embedded/jetson-linux-r3541

在矢量操作、tensorcore等操作中，尤其是当指令操作为长字段，但是操作数仅能给首寄存器的时候（注意SASS操作数和PTX操作数之间存在一定的区别，PTX更灵活，寄存器不需要连续，可以编译时重排列），数据存储时的寄存器顺序应当连续，非连续寄存器会导致寄存器间数据移动，产生大量不必要开销（显著的IMAD，MOV类型指令，在大kernel占用率不高的情况下，产生显著的 no instruction stall）
LDGDEPBAR 该barrier和 cp.async.commit_group 似乎是强绑定，但是对延迟的影响待定
block内共享内存超出48k需要使用动态共享内存设置
共享内存进行矢量操作时，似乎会出现随机冲突（指分次采样结果均不同），尤其是16字节操作时。但是进行4字节操作时不会出现冲突，即使bank已经对齐，该问题也可能由于首地址错位/错误而产生，需要经过理论位置排查
8threads 同一全局地址的boardcast会导致 uncoalse L2 和 uncoalse shared，类似于冲突和全局不对齐的行为，因此需要考虑将其均匀分布，减少同一全局位置的广播（在LDGSTS中证实存在这一现象）
异步拷贝可与计算指令执行显式异步（异步指令如LDGSTS，可以显示使用ptx等方式，可以灵活控制，由用户指定），部分同步指令，如ldmatrix与计算指令可以隐式异步（由gpu硬件执行自动指令并行，不可控）。共享内存的异步载入对延迟隐藏的效果较少，而全局内存的异步载入对延迟隐藏有显著的作用，尤其是在载入的循环量较大的时候，此效果更为明显。流水作业可以考虑2-3级
在某些情况下，即使寄存器连续，进行矢量存取时，如果采用cpp高级语言形式操作，可能会出现断裂情况，导致内存效率低下，尤其是在针对全局内存的写操作（这依赖于编译器的编译结果，尚未找到合适的提示手段）。而采用ptx st.global.v4.u32时则不会出现该问题。

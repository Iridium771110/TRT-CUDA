TRT-Plugin things
插件形式的编译中，可能出现CMAKE中某些LINK库因为未被扫描到需求而未发生链接（ldd查看无目标链接库）
此时应当使用 target_link_options(name PUBLIC "LINKER:-no-as-needed"),使指定库强行链接
猜测这个情况可能是因为注册机制导致的问题，在使用 CMAKE 编译依赖 libtorch的库时也发生了这个现象
  由于注册机制可以在不包含子类实现及头文件的情况下，仅使用父类头文件及实现库完成编译工作，可能因此导致运行时找不到子类实现但是编译及链接时没有问题（ldd也未出现 undefined symbol）的情况
  该原因仅为猜测

Plugin在各个阶段的运行顺序，针对orin trt10.5.0
buildSerialize：
  construct->suppor-check->clone->config->init->config->enqueue->terminate->destroy
  需要注意从clone开始，执行的是clone后的对象
  log中有很多重复的东西，可能内部有递归
  因为这里对clone对象进行了init，因此不会有下面infer时的init问题
  
inference:
  construct->init->clone->config->enqueue
  需要注意，此时config开始，执行的对象是clone后的那个plugin
  全部执行完毕，本engine需要释放时，clone对象destroy->原始对象terminate->原始对象destroy
  因此如果clone时调用的构造有部分操作在init内，那么可能就会导致clone的和原始对象不同，发生未初始化带来的错误

和网上部分说法可能不同的是，似乎initialize和teminate在调用内部有自关联，可能存在回调情况
configurePlugin方法可以用作部分运行时检查的手段
support-format-combination这里可以用于engine内部中间张量（本plugin的输入输出等）格式、类型等的指定，这个指定可以限定engine build过程中对计算方案的选择范围，不让格式乱飘
部分地方提示，检查设置时可能必须自小向大，不应该以比当前大的索引作为基准来检查自身，而应该以比当前小的索引作为基准检查
部分可参考文档 https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending
Tensor-setAllowedFormat 对内部中间张量不起作用，估计仅对engine输入输出进行设置时起作用
builder = createInferBuilder() 似乎会存在一定的内存泄漏（存疑，数量还不小，cpu内存），delete builder之后内存没有相应减小
plugin选择数据类型应该由输入输出描述子来直接获取而不是一个op attr

高版本如 10.5 存在对attention的图优化算子融合等操作，实际用于Superglue时发现cross-attention部分会造成大比例精度问题（并且部分帧结果不稳定，在两三种结果间跳变）怀疑存在bug
涉及norm类型的layer时，half的精度可能不够，在SuperPoint中发生build-engine时若打开fp16，有时norm部分（pow、sum等节点）全部会选择half，会导致严重的精度问题（输出0、nan等），选择float时结果正确
build-engine应当注意对格式的指定，防止部分莫名其妙错误

注意一些预编译指令的配套使用，可能会发生奇怪位置的段错误
比如 #pragma pack(x) <--> #pragma pack()应配对使用

要分析 DLA，请在使用 NVIDIA Nsight Systems CLI 时添加 --accelerator-trace nvmedia 标志
